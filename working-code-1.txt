from flask import Flask, render_template, Response, request, redirect, url_for, jsonify, session
import cv2
import numpy as np
import os
import time
from keras.models import load_model
from ultralytics import YOLO
from threading import Lock
from insightface.app import FaceAnalysis
import torch

app = Flask(__name__)
app.secret_key = 'your_secret_key'
app.config['UPLOAD_FOLDER'] = os.path.join(os.getcwd(), 'uploads')
if not os.path.exists(app.config['UPLOAD_FOLDER']):
    os.makedirs(app.config['UPLOAD_FOLDER'])

# === Models and Setup ===
crime_model = load_model("Z:\\BE-PROJECT-final\\modelnew.h5")
crime_model = crime_model.cuda() if torch.cuda.is_available() else crime_model

weapon_model = YOLO("Z:\\BE-PROJECT-final\\best.pt")
weapon_model.eval()
if torch.cuda.is_available():
    weapon_model.to('cuda')

provider = "CUDAExecutionProvider" if os.environ.get("CUDA_PATH") else "CPUExecutionProvider"
face_app = FaceAnalysis(name="buffalo_l", providers=[provider])
face_app.prepare(ctx_id=0 if provider == "CUDAExecutionProvider" else -1)
face_app.det_model.detect_size = (320, 320)

# === Criminal DB ===
criminal_db = {}
database_path = "../criminal-system/criminal_images"

def extract_embeddings(img):
    if img is None:
        return []
    img = cv2.resize(img, (640, 480))
    faces = face_app.get(img)
    if not faces:
        return []
    return [(face.embedding, face.bbox) for face in faces]

for filename in os.listdir(database_path):
    if filename.endswith((".jpg", ".png")):
        name = os.path.splitext(filename)[0]
        img = cv2.imread(os.path.join(database_path, filename))
        emb = extract_embeddings(img)
        if emb:
            criminal_db[name] = emb[0][0]

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def identify_criminal(frame, threshold=0.3):
    embeddings = extract_embeddings(frame)
    results = []
    for emb, bbox in embeddings:
        best_match = None
        best_score = -1
        for name, db_emb in criminal_db.items():
            similarity = cosine_similarity(emb, db_emb)
            if similarity > best_score:
                best_score = similarity
                best_match = name
        if best_score >= threshold:
            results.append({"name": best_match, "score": best_score, "box": list(map(int, bbox))})
    return results

def predict_crime(frame):
    frame_resized = cv2.resize(frame, (128, 128))
    frame_normalized = frame_resized / 255.0
    frame_input = np.expand_dims(frame_normalized, axis=0)
    prediction = crime_model.predict(frame_input)
    return prediction[0][0] > 0.5

def predict_weapon(frame, model):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = model(frame_rgb, verbose=False)
    weapon_detected = False
    weapon_boxes = []

    for result in results:
        boxes = result.boxes
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            label = model.names[cls_id].lower()

            if conf > 0.5 and ('weapon' in label or 'gun' in label or 'knife' in label):
                weapon_detected = True
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                weapon_boxes.append([x1, y1, x2 - x1, y2 - y1])
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, label.capitalize(), (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    return weapon_detected, weapon_boxes

# === Alerts ===
alert_message = ""
alert_lock = Lock()

@app.route('/')
def index():
    video_mode = session.get('video_mode', 'live')
    return render_template('index.html', video_mode=video_mode)

@app.route('/start', methods=['POST'])
def start():
    mode = request.form.get('mode')
    global alert_message

    with alert_lock:
        alert_message = {"type": "source", "message": "Source switched"}

    if mode == 'video':
        video = request.files.get('videoFile')
        if video and video.filename != '':
            video_path = os.path.join(app.config['UPLOAD_FOLDER'], video.filename)
            video.save(video_path)
            session['video_mode'] = 'video'
            session['video_path'] = video_path
            return redirect(url_for('video_feed'))
        else:
            session['video_mode'] = 'live'
            return redirect(url_for('index', alert="Please upload a video file."))
    else:
        session['video_mode'] = 'live'
        return redirect(url_for('video_feed'))

def generate_frames(source=None):
    global alert_message
    cap = cv2.VideoCapture(source if source is not None else 0)
    frame_count = 0
    violence_counter = 0
    start_time = None

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        # Process every 12th frame for speed
        if frame_count % 12 != 0:
            continue

        alert_triggered = False
        local_alert = ""

        # Crime Detection
        violence_detected = predict_crime(frame)
        if violence_detected:
            if start_time is None:
                start_time = time.time()
            violence_counter += 1
            if violence_counter >= 2 and (time.time() - start_time) <= 5:
                local_alert = "ðŸš¨ Crime detected (violence)"
                alert_triggered = True
                violence_counter = 0
                start_time = None
            elif (time.time() - start_time) > 5:
                violence_counter = 0
                start_time = None

        # Weapon Detection
        weapon_detected, _ = predict_weapon(frame, weapon_model)
        if weapon_detected:
            local_alert = "ðŸš¨ Weapon detected"
            alert_triggered = True

        # Criminal Detection
        criminals = identify_criminal(frame)
        for criminal in criminals:
            x, y, x2, y2 = criminal["box"]
            name = criminal["name"]
            cv2.rectangle(frame, (x, y), (x2, y2), (0, 0, 255), 2)
            cv2.putText(frame, name, (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            local_alert = f"ðŸš¨ Criminal Detected: {name}"
            alert_triggered = True

        if alert_triggered:
            with alert_lock:
                alert_message = {"type": "criminal" if "criminal" in local_alert else "violence" if "violence" in local_alert else "weapon", "message": local_alert}
        else:
            with alert_lock:
                alert_message = ""

        # Encode frame
        ret, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    cap.release()

@app.route('/video_feed')
def video_feed():
    video_mode = session.get('video_mode')
    video_path = session.get('video_path')

    if video_mode == 'video' and video_path:
        return Response(generate_frames(source=video_path),
                        mimetype='multipart/x-mixed-replace; boundary=frame')
    else:
        return Response(generate_frames(source=0),
                        mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/get_alert')
def get_alert():
    global alert_message
    with alert_lock:
        return jsonify({'alert_message': alert_message})

if __name__ == '__main__':
    app.run(debug=True)
